{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666a507f",
   "metadata": {},
   "source": [
    "Report section\n",
    "====\n",
    "\n",
    "Chosen representation & data preprocessing:\n",
    "----\n",
    "\n",
    "1. Data representation is the occurrence frequency of a word in the abstract. The reason is that the we accept the assumption that each word appears independently, and noticed that word combination are connected with \"-\" which can be regarded as one word, so we do not have to use word combination. The method to do this is just split the abstract passage with space and then we can get the result. \n",
    "2. Data preprocessing strategy is removeing common words, single charactors and numbers.   \n",
    "    Reasons:  \n",
    "    a. Common words such as \"it\", \"the\", \"a\" have no use for classification.  \n",
    "    b. Digital numbers are often data to stress in the thesis, which are unique and will very unlikely to appear again.  \n",
    "    c. Single charactors like 'a', 'b', 'c', '-', are meaningless.    \n",
    "        \n",
    "      How to achieve: \n",
    "    a. There are a couple stop words in English, I hardcoded them and put them in a list. When preprocessing, if a word is in this list, discard it.\n",
    "    b. There is a isdigit() method in python3 string class. Use it to judge if it is a digital number. If it is, discard it.\n",
    "    c. Judge the length of each word, if it is 1, then discard it.   \n",
    "    After these three steps, we can get data sets with strong characteristics。\n",
    "\n",
    "\n",
    "Method extensions and implementation(standard and extended)\n",
    "----\n",
    "1. For calculating each posterior probability, use the Bayes's theory:    \n",
    "$$\n",
    "Posterior ∝ Likelihood × Prior\n",
    "$$\n",
    "For this assignment, this equation can be applied as follows:    \n",
    "$$\n",
    "P(class | abstract) ∝ P(abstract | class) × P(class)\n",
    "$$\n",
    "\n",
    "Since the assumption is that the appearance of each word is indenpent, so the equation is follows:    \n",
    "$$\n",
    "P(class | abstract) ∝ \\prod_{i = 0}^{n} P(word_i | class) × P(class)\n",
    "$$\n",
    "\n",
    "The model will calculate the probability of each classification and choose highest one as prediction. <br>\n",
    "The theory is using the theory, maximum a posteriori:\n",
    "$$\n",
    "h_{MAP} = arg_{h∈H}[max(P(h|D)] =  arg_{h∈H}[max(\\prod_{i = 0}^{n} P(word_i | class) × P(class))]\n",
    "$$\n",
    "    \n",
    "2. Laplacian smoothing. Since not every word in the test set appears in the training set, some possibility of word can be zero. This will result in the possibility of the article in a class is zero, but there are other words in this abstract that is effective. So in order to prevent this happen, use Laplacian smoothing. This method will add 1 to every numerator and add the number of unique word plus th e number of the non-unique words. In the equation of Likelihood:\n",
    "$$\n",
    "Likelihood = \\prod_{i = 0}^{n} P(word_i | class) × P(class)\n",
    "$$\n",
    "    \n",
    "    After Laplacian smoothing, this equation will become:\n",
    "$$\n",
    "P(word_i | class) = \\frac{(wordAppearTimes+1)} {(totalCount + uniqueCount + NotUnqueCount)}\n",
    "$$    \n",
    "        \n",
    "3. Use log value to represent each possibility. For the reason that in computer, the number is discrete, if a number is very close to 0, the multiplication will be inaccurate. The possibility of each word can be really close to 0, but we can use log value to prevent the problem. Log value is monotone increasing, so it will not affect the relavent relation. And it can use add instead of multiply. So th e final equation of Posterior is:\n",
    "$$\n",
    "    \\log_2 P(class | abstract) = \\log_2 P(class) + \\sum_{i=1}^{n} \\log_2 P(word_i | class)\n",
    "$$\n",
    "\n",
    "4. For standard Naive Bayes, there is no preprocessing, no Laplacian smoothing and do not use Log to represent the probability. But for the words whose probability is 0, I did not multiply 0 and ignore them. Use the following equation:\n",
    "$$\n",
    "   P(class | abstract) ∝ \\prod_{i = 0}^{n} P(word_i | class) × P(class) \n",
    "$$\n",
    "\n",
    "    \n",
    "\n",
    "Performance (training and validation) results\n",
    "----\n",
    "1. For training and validation, this assigment use K-fold cross validation. Here, I used 5-fold, because it cost less time. The training set takes up 80% of the training data, and validation is 20%. This will insure each training set has enough data so that the validation is more useful. <br>\n",
    "2. Cross-validation score of the extended Naive Bayes model is [0.94875, 0.94875, 0.96375, 0.94125, 0.945], and the prediction of test set has 95.666% accuracy on Kaggle. \n",
    "3. And the standarded model, also use the k-fold validation to train and validate. The scores for validation are [0.24875, 0.21375, 0.24125, 0.22875, 0.175]. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2557e47b-8c34-466c-b604-6a6af2d83275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f5a934-353f-4c4e-a518-c19d6ab7ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(os.path.join(\"data\", \"trg.csv\"))\n",
    "test_set = pd.read_csv(os.path.join(\"data\", \"tst.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f87515-516f-4162-bc79-1ccb448bab62",
   "metadata": {},
   "source": [
    "## KFold class and Extended Naive Bayes Classifier\n",
    "The classifier class can be used in the following steps: first create the model, then use fit(X, y) to fit the model. Then use the predict(testSet) method to predict the result. It also has a method results_To_csv(filename) to save the prediction to a csv file which we can upload to Kaggle and see the result  \n",
    "The KFold class is used for k-fold cross validation. Fisrt create the model with the K argument to specify how many folds. Then use a for loop to iterate each training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8825f43-a7d0-4739-84c8-5dc6d3799363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBayesCLF:\n",
    "    def __init__(self):\n",
    "        self.__data_Class = {}\n",
    "        self.__each_Class_Words = {}\n",
    "        self.__each_Class_Word_Num = {}\n",
    "        self.__p = {}\n",
    "        self.__unique_Words = []\n",
    "        self.__result = []\n",
    "        self.__training_set_size = 0\n",
    "        self.__each_Class_Words_Count = {}\n",
    "        self.stop_Words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        fit the training data, X ,y\n",
    "        \"\"\"\n",
    "        for [abstract, label] in zip(X, y):\n",
    "            if label not in self.__data_Class:\n",
    "                self.__data_Class[label] = 1\n",
    "            else:\n",
    "                self.__data_Class[label] += 1\n",
    "            words = self.__preprocess(abstract.split(\" \"))\n",
    "            # words = abstract.split(\" \")\n",
    "            if label not in self.__each_Class_Words:\n",
    "                self.__each_Class_Words[label] = words\n",
    "            else:\n",
    "                self.__each_Class_Words[label] += words\n",
    "        self.__training_set_size = len(X)\n",
    "        self.__calculate_Word_count()\n",
    "        self.__calculate_Unique_Words()\n",
    "        self.__calculate_Prob_Of_Class()\n",
    "        self.__count_Each_Class_Words()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        count = 0\n",
    "        processed_WordList = []\n",
    "        for index, value in X_test.items():\n",
    "            words = self.__preprocess(value.split(\" \"))\n",
    "            # words = X_test[i].split(\" \")\n",
    "\n",
    "            processed_WordList.append(words)\n",
    "            for g in words:\n",
    "                if g not in self.__unique_Words:\n",
    "                    count += 1\n",
    "        result = []\n",
    "        for sample in processed_WordList:\n",
    "            result.append(self.__predict_Item(sample, count))\n",
    "        self.__result = result\n",
    "        return result\n",
    "\n",
    "    def __predict_Item(self, list_Words, count):\n",
    "        prob_Dict = {label: value for label, value in self.__p.items()}\n",
    "#         print(prob_Dict)\n",
    "#         print(list_Words)\n",
    "        for word in list_Words:\n",
    "            for label in prob_Dict.keys():\n",
    "                if word in self.__each_Class_Words[label]:\n",
    "                    prob_Dict[label] +=  math.log((self.__each_Class_Word_Num[label][word]+1) / (self.__each_Class_Words_Count[label] + len(self.__unique_Words) + count), 2)\n",
    "                else:\n",
    "                    prob_Dict[label] += math.log( 1 / (self.__each_Class_Words_Count[label] + len(self.__unique_Words) + count), 2)\n",
    "#         print(prob_Dict)\n",
    "        sorted_prob_Dict = sorted(prob_Dict.items(), key = lambda a: a[1], reverse = True)\n",
    "#         print(sorted_prob_Dict)\n",
    "        return sorted_prob_Dict[0][0]\n",
    "\n",
    "    def __preprocess(self, list_Words):\n",
    "        result = []\n",
    "        for word in list_Words:\n",
    "            # remove stop words\n",
    "            if word in self.stop_Words:\n",
    "                continue\n",
    "            # remove digital words like 1, 2, 3\n",
    "            if word.isdigit():\n",
    "                continue\n",
    "            # remove charactor which is meaningless\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            result.append(word)\n",
    "#         print(result)\n",
    "        return result\n",
    "\n",
    "    def results_To_csv(self, fileName):\n",
    "        df = pd.DataFrame([[id, predict] for [id, predict] in zip(range(1, len(\n",
    "            self.__result) + 1), self.__result)], columns=[\"id\", \"class\"]).to_csv(fileName, index=False)\n",
    "\n",
    "    def __calculate_Prob_Of_Class(self):\n",
    "        self.__p = {}\n",
    "        for name in self.__data_Class:\n",
    "            self.__p[name] = math.log(self.__data_Class[name] / self.__training_set_size, 2)\n",
    "#         print(self.__p)\n",
    "\n",
    "    def __calculate_Word_count(self):\n",
    "        \"\"\"\n",
    "        calculate each word appear time in each class\n",
    "        \"\"\"\n",
    "        for y in self.__data_Class.keys():\n",
    "            if y not in self.__each_Class_Word_Num:\n",
    "                self.__each_Class_Word_Num[y] = {}\n",
    "            for word in self.__each_Class_Words[y]:\n",
    "                if word not in self.__each_Class_Word_Num[y]:\n",
    "                    self.__each_Class_Word_Num[y][word] = 1\n",
    "                else:\n",
    "                    self.__each_Class_Word_Num[y][word] += 1\n",
    "        # print(self.__each_Class_Word_Num)\n",
    "\n",
    "    def __calculate_Unique_Words(self):\n",
    "        words = []\n",
    "        for y in self.__each_Class_Word_Num.keys():\n",
    "            words += self.__each_Class_Word_Num[y].keys()\n",
    "        self.__unique_Words = set(words)\n",
    "        # print(self.__unique_Words)\n",
    "    def __count_Each_Class_Words(self):\n",
    "        for label in self.__each_Class_Words:\n",
    "            self.__each_Class_Words_Count[label] = len(self.__each_Class_Words[label])\n",
    "        # print(self.__each_Class_Words_Count)\n",
    "\n",
    "    def __str__(self):\n",
    "        msg = \"\"\n",
    "        msg += f\"Class in the training set: {self.__data_Class}\\n\"\n",
    "        msg += f\"Words in each class: {self.__each_Class_Words}\\n\"\n",
    "        return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f459b78c-d6f0-4813-9378-d6b798079b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFolds:\n",
    "    def __init__(self, n_splits, shuffle = True, seed = 4321):\n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "        self.n_splits = n_splits\n",
    "    # iterable split function, call it in a for loop and it will iter each train and validation\n",
    "    def split(self, X):\n",
    "        num_Of_Samples = X.shape[0]\n",
    "        indices = np.arange(num_Of_Samples)\n",
    "        if self.shuffle:\n",
    "            random_State = np.random.RandomState(self.seed)\n",
    "            random_State.shuffle(indices)\n",
    "        for test_mask in self._iter_test_masks(num_Of_Samples, indices):\n",
    "            train_index = indices[np.logical_not(test_mask)]\n",
    "            test_index = indices[test_mask]\n",
    "            train_set = X.filter(train_index, axis = 0)\n",
    "            test_set = X.filter(test_index, axis = 0)\n",
    "            yield train_set, test_set\n",
    "        \n",
    "    def _iter_test_masks(self, num_Of_Samples, indices):\n",
    "        fold_sizes = (num_Of_Samples // self.n_splits) * np.ones(self.n_splits, dtype = np.int64)\n",
    "        fold_sizes[:num_Of_Samples % self.n_splits] += 1\n",
    "\n",
    "        current = 0\n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "            test_indices = indices[start:stop]\n",
    "            test_mask = np.zeros(num_Of_Samples, dtype = bool)\n",
    "            test_mask[test_indices] = True\n",
    "            yield test_mask\n",
    "            current = stop\n",
    "def calScore(pred_List, real_List):\n",
    "    count = 0\n",
    "    for pred, real in zip(pred_List, real_List):\n",
    "        if pred == real:\n",
    "            count += 1\n",
    "    return count / len(real_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036fa6a-8e14-48a8-9317-ccc4420bcf44",
   "metadata": {},
   "source": [
    "## Cross validation on the training set and calculate the scores of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3e760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.94875, 0.94875, 0.96375, 0.94125, 0.945]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "kfold = KFolds(5)\n",
    "for train,valid in kfold.split(training_set):\n",
    "    myCLF = MyBayesCLF()\n",
    "    myCLF.fit(X = train[\"abstract\"], y = train[\"class\"])\n",
    "    \n",
    "    result = myCLF.predict(valid[\"abstract\"])\n",
    "    score = calScore(result, valid[\"class\"])\n",
    "    scores.append(score)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ed310-f5b4-4f87-885d-15efb7b2d3bb",
   "metadata": {},
   "source": [
    "## Get the final result for prediction on the test set. Use all the training set to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84dcf337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 386, 'E': 565, 'A': 30, 'V': 19}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyBayesCLF()\n",
    "model.fit(training_set[\"abstract\"], training_set[\"class\"])\n",
    "predictions = model.predict(test_set[\"abstract\"])\n",
    "\n",
    "model.results_To_csv(\"out.csv\")\n",
    "\n",
    "count = {}\n",
    "for item in predictions:\n",
    "    if item in count:\n",
    "        count[item]+= 1\n",
    "    else:\n",
    "        count[item] = 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020de66-fdc8-45bf-8af5-7b923ae82c50",
   "metadata": {},
   "source": [
    "## Standarded Naive Bayes model and cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272459b8-f117-46f0-b7a3-40516995bc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24875, 0.21375, 0.24125, 0.22875, 0.175]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class StandardBayesCLF:\n",
    "    def __init__(self):\n",
    "        self.__data_Class = {}\n",
    "        self.__each_Class_Words = {}\n",
    "        self.__each_Class_Word_Num = {}\n",
    "        self.__p = {}\n",
    "        self.__unique_Words = []\n",
    "        self.__result = []\n",
    "        self.__training_set_size = 0\n",
    "        self.__each_Class_Words_Count = {}\n",
    "        self.stop_Words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        fit the training data, X ,y\n",
    "        \"\"\"\n",
    "        for [abstract, label] in zip(X, y):\n",
    "            if label not in self.__data_Class:\n",
    "                self.__data_Class[label] = 1\n",
    "            else:\n",
    "                self.__data_Class[label] += 1\n",
    "            words = abstract.split(\" \")\n",
    "            if label not in self.__each_Class_Words:\n",
    "                self.__each_Class_Words[label] = words\n",
    "            else:\n",
    "                self.__each_Class_Words[label] += words\n",
    "        self.__training_set_size = len(X)\n",
    "        self.__calculate_Word_count()\n",
    "        self.__calculate_Prob_Of_Class()\n",
    "        self.__count_Each_Class_Words()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        count = 0\n",
    "        processed_WordList = []\n",
    "        for index, value in X_test.items():\n",
    "            words = value.split(\" \")\n",
    "\n",
    "            processed_WordList.append(words)\n",
    "            for g in words:\n",
    "                if g not in self.__unique_Words:\n",
    "                    count += 1\n",
    "        result = []\n",
    "        for sample in processed_WordList:\n",
    "            result.append(self.__predict_Item(sample, count))\n",
    "        self.__result = result\n",
    "        return result\n",
    "\n",
    "    def __predict_Item(self, list_Words, count):\n",
    "        prob_Dict = {label: value for label, value in self.__p.items()}\n",
    "#         print(prob_Dict)\n",
    "#         print(list_Words)\n",
    "        for word in list_Words:\n",
    "            for label in prob_Dict.keys():\n",
    "                if word in self.__each_Class_Words[label]:\n",
    "                    prob_Dict[label] *=  (self.__each_Class_Word_Num[label][word]+1) / (self.__each_Class_Words_Count[label] )\n",
    "#         print(prob_Dict)\n",
    "        sorted_prob_Dict = sorted(prob_Dict.items(), key = lambda a: a[1], reverse = True)\n",
    "#         print(sorted_prob_Dict)\n",
    "        return sorted_prob_Dict[0][0]\n",
    "\n",
    "\n",
    "    def results_To_csv(self, fileName):\n",
    "        df = pd.DataFrame([[id, predict] for [id, predict] in zip(range(1, len(\n",
    "            self.__result) + 1), self.__result)], columns=[\"id\", \"class\"]).to_csv(fileName, index=False)\n",
    "\n",
    "    def __calculate_Prob_Of_Class(self):\n",
    "        self.__p = {}\n",
    "        for name in self.__data_Class:\n",
    "            self.__p[name] = self.__data_Class[name] / self.__training_set_size\n",
    "#         print(self.__p)\n",
    "\n",
    "    def __calculate_Word_count(self):\n",
    "        \"\"\"\n",
    "        calculate each word appear time in each class\n",
    "        \"\"\"\n",
    "        for y in self.__data_Class.keys():\n",
    "            if y not in self.__each_Class_Word_Num:\n",
    "                self.__each_Class_Word_Num[y] = {}\n",
    "            for word in self.__each_Class_Words[y]:\n",
    "                if word not in self.__each_Class_Word_Num[y]:\n",
    "                    self.__each_Class_Word_Num[y][word] = 1\n",
    "                else:\n",
    "                    self.__each_Class_Word_Num[y][word] += 1\n",
    "        # print(self.__each_Class_Word_Num)\n",
    "\n",
    "    def __count_Each_Class_Words(self):\n",
    "        for label in self.__each_Class_Words:\n",
    "            self.__each_Class_Words_Count[label] = len(self.__each_Class_Words[label])\n",
    "        # print(self.__each_Class_Words_Count)\n",
    "\n",
    "    def __str__(self):\n",
    "        msg = \"\"\n",
    "        msg += f\"Class in the training set: {self.__data_Class}\\n\"\n",
    "        msg += f\"Words in each class: {self.__each_Class_Words}\\n\"\n",
    "        return msg\n",
    "scores = []\n",
    "kfold = KFolds(5)\n",
    "for train,valid in kfold.split(training_set):\n",
    "    myCLF = StandardBayesCLF()\n",
    "    myCLF.fit(X = train[\"abstract\"], y = train[\"class\"])\n",
    "    \n",
    "    result = myCLF.predict(valid[\"abstract\"])\n",
    "    score = calScore(result, valid[\"class\"])\n",
    "    scores.append(score)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
